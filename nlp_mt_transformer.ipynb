{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TUBES NLP**\n",
        "### **Neural Machine Translation with Seq2Seq Architecture (Engâ†’Ina)**\n",
        "### **Menggunakan Transformer**\n",
        "\n",
        "#### Ruhiyah Faradishi Widiaputri\n",
        "#### 13519034\n"
      ],
      "metadata": {
        "id": "XTnzcjlbZngb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT NEEDED LIBRARIES"
      ],
      "metadata": {
        "id": "SgBW6ZM9Zs-l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlTWF0BCZeOt"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s0oDxpFzG2Y",
        "outputId": "528fd67f-1428-43a8-888e-bb33fc86fc83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD DATA"
      ],
      "metadata": {
        "id": "MhIbaE86y_Va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This NMT trains with ... dataset from IndoNLG ([https://github.com/IndoNLP/indonlg](https://github.com/IndoNLP/indonlg))"
      ],
      "metadata": {
        "id": "v9_xpxpYzFHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read train data\n",
        "%cd /content/drive/My Drive/Tahun 4/NLP/tubes-mt/MT_TED_MULTI/\n",
        "train_data_dir = \"train_preprocess.json\"\n",
        "val_data_dir = 'valid_preprocess.json'\n",
        "test_data_dir = 'test_preprocess.json'\n",
        "trained_model_path = 'transformer/trained_model_transformer'\n",
        "\n",
        "MAX_LENGTH = 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ_p8RFLzSax",
        "outputId": "865177bf-f2f3-4db9-c10c-323d47969047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Tahun 4/NLP/tubes-mt/MT_TED_MULTI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"UNK\", 1: \"PAD\", 2:\"SOS\", 3:\"EOS\"}\n",
        "        self.n_words = 4  # Count SOS and EOS + UNK, PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "def normalize_string(s):\n",
        "  s = s.lower()\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  return s\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) <= MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) <= MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "def load_data(filename):\n",
        "  f = open(filename)\n",
        "  json_data = json.load(f)\n",
        "  data = []\n",
        "  for j in json_data:\n",
        "    text = normalize_string(j[\"text\"])\n",
        "    label = normalize_string(j[\"label\"])\n",
        "    data.append([text, label])\n",
        "  return data\n",
        "\n",
        "# define input and output lang\n",
        "input_lang = Lang(\"en\")\n",
        "output_lang = Lang(\"ina\")\n",
        "\n",
        "# load + normalize train data\n",
        "train_data = load_data(train_data_dir)\n",
        "\n",
        "# check how many sentence pairs\n",
        "print(\"Read %s sentence pairs\" % len(train_data))\n",
        "\n",
        "# take only data train with len < 20\n",
        "train_data = filterPairs(train_data)\n",
        "print(\"Trimmed to %s sentence pairs\" % len(train_data))\n",
        "  \n",
        "# add vocabulary\n",
        "for tr in train_data:\n",
        "  input_lang.addSentence(tr[0])\n",
        "  output_lang.addSentence(tr[1])\n",
        "\n",
        "print(\"Counted words:\")\n",
        "print(input_lang.name, input_lang.n_words)\n",
        "print(output_lang.name, output_lang.n_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_kZRVGyzBL3",
        "outputId": "54ff413b-080d-4d98-ebff-f8d0e8cd31f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 87406 sentence pairs\n",
            "Trimmed to 40063 sentence pairs\n",
            "Counted words:\n",
            "en 17727\n",
            "ina 16808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load validation data\n",
        "# load + normalize train data\n",
        "val_data = load_data(val_data_dir)\n",
        "\n",
        "# check how many sentence pairs\n",
        "print(\"Read %s sentence pairs\" % len(val_data))\n",
        "\n",
        "# take only data train with len < 20\n",
        "val_data = filterPairs(val_data)\n",
        "print(\"Trimmed to %s sentence pairs\" % len(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZzOTjXQ-vfc",
        "outputId": "1095695c-ba49-404a-ef41-0737c2827c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 2677 sentence pairs\n",
            "Trimmed to 1304 sentence pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SEQ2SEQ MODEL DENGAN TRANSFORMERS"
      ],
      "metadata": {
        "id": "kn9QRbN1Z33y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # den = 1/(10000^(2i/dmodel))\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "\n",
        "        # position\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "\n",
        "        # pos_embedding\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        # P E(pos,2i) = sin(pos/1000^(2i/dim_model))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        # P E(pos,2i+1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "\n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_embedding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
      ],
      "metadata": {
        "id": "Fj8G8AZbZ7NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seq2Seq Network \n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "\n",
        "        # embedding size\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "        # positional encoding untuk source maupun target\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "        \n",
        "        # embedding layer\n",
        "        self.embedding = nn.Embedding(src_vocab_size, emb_size)\n",
        "\n",
        "        # model Transformer yang sudah disediakan pytorch\n",
        "        self.transformer = Transformer(d_model=emb_size,                      # banyak fitur untuk masukan encoder/ decoder (default = 512)\n",
        "                                       nhead=nhead,                           # banyak head di multihead attention (default=8)\n",
        "                                       num_encoder_layers=num_encoder_layers, # banyak sub-encoder layer di encoder (default=6)\n",
        "                                       num_decoder_layers=num_decoder_layers, # banyak sub-decoder layer di decoder (default=6)\n",
        "                                       dim_feedforward=dim_feedforward,       # dimensi FFNN (Default=2048)\n",
        "                                       dropout=dropout)                       # nilai dropout (default=0.1)\n",
        "        \n",
        "        # linear layer yang menerima keluaran decoder transformer\n",
        "        self.out = nn.Linear(emb_size, tgt_vocab_size)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor, # (batch_size, src sequence length, dim_model)\n",
        "                tgt: Tensor, # (batch_size, src sequence length, dim_model)\n",
        "                tgt_mask=None,\n",
        "                src_padding_mask= None,\n",
        "                tgt_padding_mask= None):\n",
        "      \n",
        "        # buat positional encoding untuk token embedding untuk source\n",
        "        src_emb = self.embedding(src) * math.sqrt(self.emb_size)\n",
        "        src_emb = self.positional_encoding(src_emb)\n",
        "\n",
        "        # buat positional encoding untuk token embedding untuk target\n",
        "        tgt_emb = self.embedding(tgt) * math.sqrt(self.emb_size)\n",
        "        tgt_emb = self.positional_encoding(tgt_emb)\n",
        "\n",
        "        # permute untuk mendapat ukuran (sequence length, batch_size, dim_model),\n",
        "        # print(src_emb)\n",
        "        # print(src_emb.shape)\n",
        "        src_emb = src_emb.permute(1, 0, 2)\n",
        "        tgt_emb = tgt_emb.permute(1, 0, 2)\n",
        "\n",
        "        # lanjut forward proses untuk transformer\n",
        "        outs = self.transformer(src_emb,                # sekuens encoder (Tensor: required)\n",
        "                                tgt_emb,                # sekuens decoder (Tensor: required)\n",
        "                                tgt_mask,               # mask tambahan untuk sekuens target ([Tensor] : optional)\n",
        "                                None,                   # mask tambahan untuk keluaran encoder = None\n",
        "                                src_padding_mask,       # ByteTensor mask untuk source keys per batch ([Tensor]: optional)\n",
        "                                tgt_padding_mask)       # ByteTensor mask untuk target keys per batch ([Tensor]: optional)\n",
        "        \n",
        "        # lanjut ke linear layer akhir\n",
        "        return self.out(outs)\n",
        "\n",
        "    def get_tgt_mask(self, size) -> torch.tensor:\n",
        "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
        "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
        "        return mask\n",
        "\n",
        "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
        "        return (matrix == pad_token)"
      ],
      "metadata": {
        "id": "HSM-eV2Sdqgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definisikan parameter-parameter model\n",
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = input_lang.n_words\n",
        "TGT_VOCAB_SIZE = output_lang.n_words\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3"
      ],
      "metadata": {
        "id": "_9aqovqdyHPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defenisikan model, loss function, dan optimizer\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, \n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "metadata": {
        "id": "nkjHvBBa08YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING"
      ],
      "metadata": {
        "id": "0EISYKF7K236"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mengambil indeks dari setiap kata di sentence --> hasilnya list of indeks kata\n",
        "def arrFromSentence(lang, sentence):\n",
        "    kals = [word for word in sentence.split(' ')]\n",
        "    l = len(kals)\n",
        "    res = np.ones(MAX_LENGTH+2)\n",
        "    res[0] = 2\n",
        "    for i in range(l):\n",
        "      if kals[i] in lang.word2index:\n",
        "        res[i+1] = int(lang.word2index[kals[i]])\n",
        "      else:\n",
        "        res[i+1] = 0\n",
        "    res[l] = 3\n",
        "    \n",
        "    return res\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "  return torch.from_numpy(arrFromSentence(lang, sentence))\n",
        "\n",
        "SOS_token = np.array([2])\n",
        "EOS_token = np.array([3])\n",
        "\n",
        "#UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "\n",
        "# mengembalikan tuple (input, target)\n",
        "def arrFromPair(pair):\n",
        "    input = arrFromSentence(input_lang, pair[0])\n",
        "    target = arrFromSentence(output_lang, pair[1])\n",
        "    return [input, target]\n",
        "\n",
        "def batchify_data(data, padding=False, padding_token=-1):\n",
        "    batches = []\n",
        "    for idx in range(0, len(data), BATCH_SIZE):\n",
        "        # We make sure we dont get the last bit if its not batch_size size\n",
        "        if idx + BATCH_SIZE < len(data):\n",
        "            # Here you would need to get the max length of the batch,\n",
        "            # and normalize the length with the PAD token.\n",
        "            if padding:\n",
        "                max_batch_length = 0\n",
        "\n",
        "                # Get longest sentence in batch\n",
        "                for seq in data[idx : idx + BATCH_SIZE]:\n",
        "                    if len(seq) > max_batch_length:\n",
        "                        max_batch_length = len(seq)\n",
        "\n",
        "                # Append X padding tokens until it reaches the max length\n",
        "                for seq_idx in range(BATCH_SIZE):\n",
        "                    remaining_length = BATCH_SIZE - len(data[idx + seq_idx])\n",
        "                    data[idx + seq_idx] += [padding_token] * remaining_length\n",
        "\n",
        "            batches.append(np.array(data[idx : idx + BATCH_SIZE]).astype(np.int64))\n",
        "\n",
        "    print(f\"{len(batches)} batches of size {BATCH_SIZE}\")\n",
        "\n",
        "    return batches"
      ],
      "metadata": {
        "id": "xki_2grw_miS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "training_pairs = [arrFromPair(td) for td in train_data]\n",
        "train_dataloader = batchify_data(training_pairs)\n",
        "\n",
        "# validation\n",
        "val_pairs = [arrFromPair(td) for td in val_data]\n",
        "val_dataloader = batchify_data(val_pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AwFM863ijli",
        "outputId": "9b2f0f1e-13b9-4308-c492-561103281380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "312 batches of size 128\n",
            "10 batches of size 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, opt, loss_fn, dataloader):\n",
        "    \n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for batch in dataloader:\n",
        "        X, y = batch[:, 0], batch[:, 1]\n",
        "        X, y = torch.tensor(X).to(DEVICE), torch.tensor(y).to(DEVICE)\n",
        "\n",
        "        # shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "        y_input = y[:,:-1]\n",
        "        y_expected = y[:,1:]\n",
        "        \n",
        "        # Get mask to mask out the next words\n",
        "        sequence_length = y_input.size(1)\n",
        "        tgt_mask = model.get_tgt_mask(sequence_length+1).to(DEVICE)\n",
        "\n",
        "        # Standard training except we pass in y_input and tgt_mask\n",
        "        pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "        # Permute pred to have batch size first again\n",
        "        pred = pred.permute(1, 2, 0)      \n",
        "        loss = loss_fn(pred, y_expected)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    \n",
        "        total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "9c88NTQKPPWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_loop(model, loss_fn, dataloader):\n",
        "    \n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            X, y = batch[:, 0], batch[:, 1]\n",
        "            X, y = torch.tensor(X, dtype=torch.long, device=DEVICE), torch.tensor(y, dtype=torch.long, device=DEVICE)\n",
        "\n",
        "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "            y_input = y[:,:-1]\n",
        "            y_expected = y[:,1:]\n",
        "            \n",
        "            # Get mask to mask out the next words\n",
        "            sequence_length = y_input.size(1)\n",
        "            tgt_mask = model.get_tgt_mask(sequence_length+1).to(DEVICE)\n",
        "\n",
        "            # Standard training except we pass in y_input and src_mask\n",
        "            pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "            # Permute pred to have batch size first again\n",
        "            pred = pred.permute(1, 2, 0)      \n",
        "            loss = loss_fn(pred, y_expected)\n",
        "            total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "qLEUUWcoPq67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 6\n",
        "\n",
        "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
        "    \n",
        "    # Used for plotting later on\n",
        "    train_loss_list, validation_loss_list = [], []\n",
        "    \n",
        "    print(\"Training and validating model\")\n",
        "    for epoch in range(epochs):\n",
        "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
        "        \n",
        "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
        "        train_loss_list += [train_loss]\n",
        "        \n",
        "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
        "        validation_loss_list += [validation_loss]\n",
        "        \n",
        "        print(f\"Training loss: {train_loss:.4f}\")\n",
        "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
        "        print()\n",
        "\n",
        "        # save model\n",
        "        torch.save(model.state_dict(), f\"{trained_model_path}_epoch:{epoch}.pt\")\n",
        "        \n",
        "    return train_loss_list, validation_loss_list\n",
        "    \n",
        "train_loss_list, validation_loss_list = fit(transformer, optimizer, loss_fn, train_dataloader, val_dataloader, NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHLWwNPgP0GF",
        "outputId": "8cd5eb0b-52f5-48a1-c4b4-66c328e4f2cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and validating model\n",
            "------------------------- Epoch 1 -------------------------\n",
            "Training loss: 2.8021\n",
            "Validation loss: 2.5928\n",
            "\n",
            "------------------------- Epoch 2 -------------------------\n",
            "Training loss: 2.4014\n",
            "Validation loss: 2.3377\n",
            "\n",
            "------------------------- Epoch 3 -------------------------\n",
            "Training loss: 2.1299\n",
            "Validation loss: 2.1552\n",
            "\n",
            "------------------------- Epoch 4 -------------------------\n",
            "Training loss: 1.9162\n",
            "Validation loss: 2.0075\n",
            "\n",
            "------------------------- Epoch 5 -------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD THE MODEL"
      ],
      "metadata": {
        "id": "45_90vVJ_jAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# redefine the model\n",
        "transformer_trained = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, \n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "# load encoder trained model\n",
        "transformer_trained.load_state_dict(torch.load(f\"{trained_model_path}_epoch:3.pt\"))\n",
        "transformer_trained.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "685lWpzg_iO7",
        "outputId": "b00515e0-9eae-45f6-e772-08ae6eef2ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqTransformer(\n",
              "  (positional_encoding): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (embedding): Embedding(17727, 512)\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (2): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (2): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (out): Linear(in_features=512, out_features=16808, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    }
  ]
}